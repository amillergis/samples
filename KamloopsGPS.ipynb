{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import os\n",
    "import re\n",
    "from datetime import time, timedelta, date, datetime\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from shapely.geometry import Point, LineString\n",
    "from geopandas import GeoDataFrame\n",
    "#########################################################################################\n",
    "# Matching Parameters\n",
    "DRIVEBY_TOLERANCE = 400  # meters. Used to define the catchment area of a bus stop\n",
    "TIME_TOLERANCE = 15 # minutes.  Used to define the +/- value for matching to the GTFS schedule Start End Points\n",
    "\n",
    "# Filter Paramaters\n",
    "ROUTE_DEVIATION = 10 # meters.  Used to filter potential trips by their average deviation(RMS) from the route geometry\n",
    "TIME_DEVIATION = timedelta(minutes=30) # Used to filter potential trips by their average deviation(RMS) from the GTFS schedule\n",
    "#########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep GPS Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding GPS files\n",
      "Found 13 files\n",
      "processing 201-020817.txt\n",
      "processing 202-021217.txt\n",
      "processing 204-021017.txt\n",
      "processing 205-021517.txt\n",
      "processing 206-020217.txt\n",
      "processing 208-021217.txt\n",
      "processing 209-020617.txt\n",
      "processing 210-030717.txt\n",
      "processing 211-021217.txt\n",
      "processing 213-021217.txt\n",
      "processing 214-021217.txt\n",
      "processing 216-020917.txt\n",
      "processing 217-022317.txt\n",
      "Converting Degrees/Minutes/Seconds to Decimal Degrees\n",
      "Adding Geometry\n",
      "Exporting to shape\n",
      "Calculating Service Days\n",
      "Add a Timestamp Index\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Finding GPS files')\n",
    "gps_files = [f for f in os.listdir(r'\\Data') if f.endswith('txt')]\n",
    "print('Found {0} files'.format(len(gps_files)))\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "for f in gps_files:\n",
    "    unit = f[:3]\n",
    "    print(\"processing {0}\".format(f))\n",
    "    df = pd.read_csv(r'\\Data\\{0}'.format(f),header=None,encoding='latin', \n",
    "                     names=['Date','Time','Latitude','Longitude','Speed','Direction','Elevation'], infer_datetime_format=True,\n",
    "                     parse_dates={'Timestamp':[0,1]})\n",
    "    df['Unit'] = unit\n",
    "    dataframe = dataframe.append(df)\n",
    "    \n",
    "print('Converting Degrees/Minutes/Seconds to Decimal Degrees')\n",
    "def dms2dd(measure):\n",
    "    dms_list = re.split('[\\sÂ°\\'\"]+', measure)\n",
    "    if dms_list[0] == 'W':\n",
    "        return(-1*(float(dms_list[1])+((float(dms_list[2])+(float(dms_list[3])/60))/60)))\n",
    "    else:\n",
    "        return(float(dms_list[1])+((float(dms_list[2])+(float(dms_list[3])/60))/60))\n",
    "\n",
    "dataframe['Latitude'] = [dms2dd(dms) for dms in dataframe['Latitude']]\n",
    "dataframe['Longitude'] = [dms2dd(dms) for dms in dataframe['Longitude']]\n",
    "\n",
    "print('Adding Geometry')\n",
    "dataframe['geometry'] = [Point(x.Longitude,x.Latitude) for x in dataframe.itertuples()]\n",
    "dataframe = GeoDataFrame(dataframe)\n",
    "dataframe.crs = {'init': 'epsg:4326', 'no_defs': True}\n",
    "dataframe.to_crs(epsg=3005, inplace=True)\n",
    "\n",
    "shpframe = dataframe.copy()\n",
    "shpframe.Timestamp = shpframe.Timestamp.astype('str')\n",
    "\n",
    "print('Exporting to shape')\n",
    "shpframe.to_file('data.shp')\n",
    "\n",
    "print('Calculating Service Days')\n",
    "dataframe['ServiceDay'] = [sd.date() if sd.time() > time(4) else (sd.date()-timedelta(days=1)) for sd in dataframe.Timestamp]\n",
    "\n",
    "print('Add a Timestamp Index')\n",
    "dataframe.set_index('Timestamp', drop=False, inplace=True)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define GTFS object \n",
    "class GTFS(object):\n",
    "    \"\"\"Create an object to represent the package of GTFS files\"\"\"\n",
    "    def __init__(self, input_file):\n",
    "        #Read the source GTFS files from zip\n",
    "        if zipfile.is_zipfile(input_file):\n",
    "            with zipfile.ZipFile(input_file, 'r') as gtfs_zip:\n",
    "                with gtfs_zip.open('agency.txt') as agency:\n",
    "                    self.agency = pd.read_csv(agency)\n",
    "                with gtfs_zip.open('calendar.txt') as calendar:\n",
    "                    self.calendar = pd.read_csv(\n",
    "                            calendar,\n",
    "                            parse_dates=['start_date','end_date'],\n",
    "                            infer_datetime_format=True)\n",
    "                with gtfs_zip.open('calendar_dates.txt') as calendar_dates:\n",
    "                    self.calendar_dates = pd.read_csv(\n",
    "                        calendar_dates,\n",
    "                        parse_dates=['date',],\n",
    "                        infer_datetime_format=True)\n",
    "                with gtfs_zip.open('feed_info.txt') as feed_info:\n",
    "                    self.feed_info = pd.read_csv(feed_info)\n",
    "                with gtfs_zip.open('routes.txt') as routes:\n",
    "                    self.routes = pd.read_csv(routes)\n",
    "                with gtfs_zip.open('shapes.txt') as shapes:\n",
    "                    self.shapes = pd.read_csv(shapes)\n",
    "                with gtfs_zip.open('stop_times.txt') as stop_times:\n",
    "                    self.stop_times = pd.read_csv(\n",
    "                            stop_times,\n",
    "                            parse_dates=['arrival_time','departure_time'],\n",
    "                            infer_datetime_format=True)\n",
    "                with gtfs_zip.open('stops.txt') as stops:\n",
    "                    self.stops = pd.read_csv(stops)\n",
    "                with gtfs_zip.open('trips.txt') as trips:\n",
    "                    self.trips = pd.read_csv(trips)\n",
    "        \n",
    "        # Or read the source GTFS files from folder\n",
    "        else:\n",
    "            self.agency = pd.read_csv(input_file + 'agency.txt')\n",
    "            self.calendar = pd.read_csv(\n",
    "                    input_file + 'calendar.txt',\n",
    "                    parse_dates=['start_date','end_date'],\n",
    "                    infer_datetime_format=True)\n",
    "            self.calendar_dates = pd.read_csv(\n",
    "                    input_file + 'calendar_dates.txt',\n",
    "                    parse_dates=['date',],\n",
    "                    infer_datetime_format=True)\n",
    "            self.feed_info = pd.read_csv(input_file + 'feed_info.txt')\n",
    "            self.routes = pd.read_csv(input_file + 'routes.txt')\n",
    "            self.shapes = pd.read_csv(input_file + 'shapes.txt')\n",
    "            self.stop_times = pd.read_csv(\n",
    "                    input_file + 'stop_times.txt',\n",
    "                    parse_dates=['arrival_time','departure_time'],\n",
    "                    infer_datetime_format=True)\n",
    "            self.stops = pd.read_csv(input_file + 'stops.txt')\n",
    "            self.trips = pd.read_csv(input_file + 'trips.txt')\n",
    "        \n",
    "        # Add Geometry to stops and shapes\n",
    "        self.stops['geometry'] = self.stops.apply(lambda x: Point(float(x.stop_lon), float(x.stop_lat)), axis=1)\n",
    "        self.stops = GeoDataFrame(self.stops)\n",
    "        self.stops.crs = {'init': 'epsg:4326', 'no_defs': True}\n",
    "        self.stops.to_crs(epsg=3005, inplace=True)\n",
    "        \n",
    "        # Could improve timing of these three or four lines\n",
    "        self.shapes['geometry'] = self.shapes.apply(lambda x: Point(float(x.shape_pt_lon), float(x.shape_pt_lat)), axis=1)\n",
    "        self.shapes = self.shapes.groupby('shape_id').aggregate(lambda x: tuple(x)).geometry.apply(lambda x: LineString(x))\n",
    "        self.shapes = GeoDataFrame(self.shapes)\n",
    "        self.shapes.crs = {'init': 'epsg:4326', 'no_defs': True}\n",
    "        self.shapes.to_crs(epsg=3005, inplace=True)\n",
    "     \n",
    "    def trips_by_date(self,service_date):\n",
    "        \"\"\"Return a list of the GTFS trips active for a specific date\"\"\"\n",
    "        flat_gtfs = pd.merge(\n",
    "                pd.merge(self.calendar,self.calendar_dates,on='service_id', how='outer'),\n",
    "                self.trips,\n",
    "                on='service_id',\n",
    "                how='outer'\n",
    "        )\n",
    "\n",
    "        # Base Service\n",
    "        base_trips = flat_gtfs[\n",
    "                (flat_gtfs.start_date <= service_date) & \n",
    "                (flat_gtfs.end_date >= service_date) & \n",
    "                (flat_gtfs[service_date.strftime('%A').lower()] == 1)\n",
    "        ]\n",
    "\n",
    "        # trips to add\n",
    "        add_trips = flat_gtfs[(flat_gtfs.date==service_date)&(flat_gtfs.exception_type==1)]\n",
    "\n",
    "        # trips to remove\n",
    "        remove_trips = flat_gtfs[(flat_gtfs.date==service_date)&(flat_gtfs.exception_type==2)]\n",
    "\n",
    "        trips = pd.concat([base_trips,add_trips])\n",
    "        trips = pd.merge(trips,remove_trips,on=['trip_id','service_id'],how='left',indicator=True)\n",
    "        trips = trips[trips._merge == 'left_only']\n",
    "        trips.drop_duplicates(subset='trip_id')\n",
    "        \n",
    "        return(trips)\n",
    "    \n",
    "    def stop_times_by_date(self,service_date):\n",
    "        \"\"\"Return a list of stopids and times for a specific date\"\"\"\n",
    "        trips = self.trips_by_date(service_date)\n",
    "        return(pd.merge(trips,self.stop_times,on='trip_id'))\n",
    "\n",
    "    def start_points(self,by_date=None):\n",
    "        start_points = None\n",
    "        \n",
    "        if by_date:\n",
    "            stop_times = self.stop_times_by_date(by_date)\n",
    "        else:\n",
    "            stop_times = self.stop_times\n",
    "        \n",
    "        if len(stop_times) > 0:\n",
    "            start_points = stop_times[stop_times.stop_sequence==1]\n",
    "            start_points = pd.merge(start_points,self.stops,on='stop_id')\n",
    "            start_points = start_points.rename(columns = {'arrival_time':'start_time','stop_id':'start_stop'})\n",
    "        return (start_points)\n",
    "\n",
    "    def end_points(self,by_date=None):\n",
    "        end_points = None\n",
    "        \n",
    "        if by_date:\n",
    "            stop_times = self.stop_times_by_date(by_date)\n",
    "        else:\n",
    "            stop_times = self.stop_times\n",
    "        \n",
    "        if len(stop_times) > 0:\n",
    "            end_points = pd.merge(stop_times,stop_times.groupby('trip_id').max().reset_index(),on='trip_id',suffixes=('','_max'))\n",
    "            end_points = end_points[end_points.stop_sequence == end_points.stop_sequence_max]\n",
    "            end_points = pd.merge(end_points,Schedule.stops,on='stop_id')\n",
    "            end_points = end_points.rename(columns = {'arrival_time':'end_time','stop_id':'end_stop'})\n",
    "        return (end_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Schedule = GTFS(\n",
    "        r'Kamloops_20170125.zip'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO skip all the start stop end stop crap and just find the start and finish of the trip\n",
    "# Merge intermediate frames together to create a table with geometry for the start and and points as well as the trip shape line\n",
    "AllTrips = pd.merge(Schedule.start_points(by_date=date(2017,2,3)),\n",
    "                    Schedule.end_points(by_date=date(2017,2,3)), \n",
    "                    on='trip_id', suffixes=('_start','_end'))\n",
    "\n",
    "AllTrips = pd.merge(AllTrips,Schedule.trips[['trip_id','shape_id']],on='trip_id')\n",
    "Schedule.shapes['shape_id'] = Schedule.shapes.index\n",
    "AllTrips = pd.merge(AllTrips,Schedule.shapes,on='shape_id')\n",
    "AllTrips = AllTrips.drop_duplicates(subset='trip_id').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ServiceDay = date(2017,2,3)\n",
    "\n",
    "data = dataframe[(dataframe.ServiceDay==ServiceDay) & (dataframe.Unit=='201')]\n",
    "\n",
    "###TODO- TOO SLOW!!!!!\n",
    "\n",
    "def find_trip_start(row,apc_data):\n",
    "    \"\"\"\n",
    "        Takes a trip starting time and selects window of APC data based on the defined interval to scan for potential matches.\n",
    "        Returns the timestamp from the last record where the bus was within the specified distance of the starting location OR\n",
    "        returns None if no potential matches are found.\n",
    "    \"\"\"\n",
    "    possible_start_points = []\n",
    "   \n",
    "    hour = int(row.start_time[0:2])\n",
    "    minute = int(row.start_time[3:5])\n",
    "    second = int(row.start_time[6:8])\n",
    "    \n",
    "    if hour < 24:\n",
    "        scheduled_start = datetime.combine(ServiceDay,time(hour,minute,second))\n",
    "    else:\n",
    "        hour -= 24\n",
    "        scheduled_start = datetime.combine(ServiceDay,time(hour,minute,second)) + timedelta(1)\n",
    "    \n",
    "    lower_bound = scheduled_start-timedelta(minutes=TIME_TOLERANCE)\n",
    "    upper_bound = scheduled_start+timedelta(minutes=TIME_TOLERANCE)\n",
    "    \n",
    "    # create a subset of APC data for the requested time period i.e. Plus or minus the TIME_TOLERANCE from the trip start time\n",
    "    possible_start_points=apc_data[lower_bound:upper_bound].copy()\n",
    "\n",
    "    # Assuming we have a subset of data\n",
    "    if len(possible_start_points) > 0:\n",
    "        # Check distance.  Adjust DRIVEBY_TOLERANCE so that we have a reasonable chance of catching \"Drive By\" datapoints \n",
    "        matching_start_points = possible_start_points[\n",
    "                possible_start_points.geometry.distance(row.geometry_start) < DRIVEBY_TOLERANCE\n",
    "        ]\n",
    "        if len(matching_start_points) > 0:\n",
    "            # Return the most recent timestamp i.e. the last point within DRIVEBY_TOLERANCE of the trip start\n",
    "            ##TODO - This is where the error concerning trip start times is being created\n",
    "            trip_start = matching_start_points.tail(1)\n",
    "            return trip_start.Timestamp\n",
    "\n",
    "def find_trip_end(row,apc_data):\n",
    "    \"\"\"\n",
    "        Takes a trip ending time and selects a window of APC data based on the defined interval to scan for potential matches.\n",
    "        Returns the timestamp from the most first record where the bus was within the specified distance of the ending location \n",
    "        OR returns None if no potential matches are found.\n",
    "    \"\"\"\n",
    "    possible_end_points = []\n",
    "\n",
    "    hour = int(row.end_time[0:2])\n",
    "    minute = int(row.end_time[3:5])\n",
    "    second = int(row.end_time[6:8])\n",
    "    \n",
    "    if hour < 24:\n",
    "        scheduled_end = datetime.combine(ServiceDay,time(hour,minute,second))\n",
    "    else:\n",
    "        hour -= 24\n",
    "        scheduled_end = datetime.combine(ServiceDay,time(hour,minute,second)) + timedelta(1)\n",
    "\n",
    "    lower_bound = scheduled_end-timedelta(minutes=TIME_TOLERANCE)\n",
    "    upper_bound = scheduled_end+timedelta(minutes=TIME_TOLERANCE)\n",
    "    \n",
    "    # create a subset of APC data for the requested time period i.e. Plus or minus the TIME_TOLERANCE from the trip start time\n",
    "    possible_end_points=apc_data[lower_bound:upper_bound].copy()\n",
    " \n",
    "    #Assuming we have a subset of data\n",
    "    if len(possible_end_points) > 0:\n",
    "        # Check distance.  Adjust DRIVEBY_TOLERANCE so that we have a reasonable chance of catching \"Drive By\" datapoints \n",
    "        matching_end_points = possible_end_points[possible_end_points.geometry.distance(row.geometry_end) < DRIVEBY_TOLERANCE]\n",
    "    \n",
    "        if len(matching_end_points) > 0:\n",
    "            # Return the oldest timestamp. i.e. the first point within DRIVEBY_TOLERANCE of the trip start\n",
    "            ##TODO - This is where the error concerning trip end times is being created\n",
    "            trip_end = matching_end_points.head(1)\n",
    "            return trip_end.Timestamp\n",
    "\n",
    "\n",
    "# Apply the find actual start and end time functions to each trip\n",
    "AllTrips['actual_start'] = [find_trip_start(x,data) for x in AllTrips.itertuples()]\n",
    "AllTrips['actual_end'] = [find_trip_end(x,data) for x in AllTrips.itertuples()]\n",
    "\n",
    "# Create a subset of the possible trips by removing trips that do not meet the start and end points of the trip within the \n",
    "# specified TIME_TOLERANCE\n",
    "# More useful for non-blocked matching\n",
    "# Changed this to or to open up matching\n",
    "FirstFilterTrips = AllTrips.loc[(AllTrips.actual_start.notnull()) & (AllTrips.actual_end.notnull())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ServiceDay = date(2017,2,3)\n",
    "\n",
    "\n",
    "def calculate_ShapeRMS(row, apc_data):\n",
    "    \"\"\" \n",
    "        Extracts all of the data points comprising each potential trip from the APC data and compares \n",
    "        them to the trip geometry.  Returns the RMS value based on how closely the data points match the trip shape.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract APC data subset based on trip \"actual\" start and end points representing the trip\n",
    "    trip_points = apc_data[row.actual_start[0]:row.actual_end[0]].copy()\n",
    "    if len(trip_points) > 0:\n",
    "        # Calculate the spatial RMS from the trip shape geometry.\n",
    "        trip_points['deviation'] = trip_points.apply(lambda x: x.geometry.distance(row.geometry),axis=1)\n",
    "        trip_points['squared_deviation'] = trip_points.apply(lambda x: x.deviation**2,axis=1)\n",
    "        variance = trip_points.squared_deviation.mean()\n",
    "        RMS = sqrt(variance)\n",
    "        return RMS\n",
    "\n",
    "FirstFilterTrips['ShapeRMS'] = [calculate_ShapeRMS(x,data) for x in FirstFilterTrips.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SecondFilterTrips = FirstFilterTrips[FirstFilterTrips.ShapeRMS < ROUTE_DEVIATION].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp\n",
       "2017-02-03 06:45:06   2017-02-03 06:45:06\n",
       "2017-02-03 06:45:07   2017-02-03 06:45:07\n",
       "2017-02-03 06:45:08   2017-02-03 06:45:08\n",
       "2017-02-03 06:45:09   2017-02-03 06:45:09\n",
       "2017-02-03 06:45:10   2017-02-03 06:45:10\n",
       "2017-02-03 06:45:11   2017-02-03 06:45:11\n",
       "2017-02-03 06:45:12   2017-02-03 06:45:12\n",
       "2017-02-03 06:45:13   2017-02-03 06:45:13\n",
       "2017-02-03 06:45:14   2017-02-03 06:45:14\n",
       "2017-02-03 06:45:15   2017-02-03 06:45:15\n",
       "2017-02-03 06:45:16   2017-02-03 06:45:16\n",
       "2017-02-03 06:45:17   2017-02-03 06:45:17\n",
       "2017-02-03 06:45:18   2017-02-03 06:45:18\n",
       "2017-02-03 06:45:19   2017-02-03 06:45:19\n",
       "2017-02-03 06:45:20   2017-02-03 06:45:20\n",
       "2017-02-03 06:45:21   2017-02-03 06:45:21\n",
       "2017-02-03 06:45:22   2017-02-03 06:45:22\n",
       "2017-02-03 06:45:23   2017-02-03 06:45:23\n",
       "2017-02-03 06:45:24   2017-02-03 06:45:24\n",
       "2017-02-03 06:45:25   2017-02-03 06:45:25\n",
       "2017-02-03 06:45:26   2017-02-03 06:45:26\n",
       "2017-02-03 06:45:27   2017-02-03 06:45:27\n",
       "2017-02-03 06:45:28   2017-02-03 06:45:28\n",
       "2017-02-03 06:45:29   2017-02-03 06:45:29\n",
       "2017-02-03 06:45:30   2017-02-03 06:45:30\n",
       "2017-02-03 06:45:31   2017-02-03 06:45:31\n",
       "2017-02-03 06:45:32   2017-02-03 06:45:32\n",
       "2017-02-03 06:45:52   2017-02-03 06:45:52\n",
       "2017-02-03 06:45:53   2017-02-03 06:45:53\n",
       "2017-02-03 06:48:46   2017-02-03 06:48:46\n",
       "                              ...        \n",
       "2017-02-03 23:08:19   2017-02-03 23:08:19\n",
       "2017-02-03 23:08:20   2017-02-03 23:08:20\n",
       "2017-02-03 23:08:21   2017-02-03 23:08:21\n",
       "2017-02-03 23:08:22   2017-02-03 23:08:22\n",
       "2017-02-03 23:08:23   2017-02-03 23:08:23\n",
       "2017-02-03 23:08:24   2017-02-03 23:08:24\n",
       "2017-02-03 23:08:25   2017-02-03 23:08:25\n",
       "2017-02-03 23:08:26   2017-02-03 23:08:26\n",
       "2017-02-03 23:08:27   2017-02-03 23:08:27\n",
       "2017-02-03 23:08:28   2017-02-03 23:08:28\n",
       "2017-02-03 23:08:29   2017-02-03 23:08:29\n",
       "2017-02-03 23:08:30   2017-02-03 23:08:30\n",
       "2017-02-03 23:08:31   2017-02-03 23:08:31\n",
       "2017-02-03 23:08:32   2017-02-03 23:08:32\n",
       "2017-02-03 23:08:33   2017-02-03 23:08:33\n",
       "2017-02-03 23:08:34   2017-02-03 23:08:34\n",
       "2017-02-03 23:08:35   2017-02-03 23:08:35\n",
       "2017-02-03 23:08:36   2017-02-03 23:08:36\n",
       "2017-02-03 23:08:37   2017-02-03 23:08:37\n",
       "2017-02-03 23:08:38   2017-02-03 23:08:38\n",
       "2017-02-03 23:08:39   2017-02-03 23:08:39\n",
       "2017-02-03 23:08:40   2017-02-03 23:08:40\n",
       "2017-02-03 23:08:41   2017-02-03 23:08:41\n",
       "2017-02-03 23:08:42   2017-02-03 23:08:42\n",
       "2017-02-03 23:08:43   2017-02-03 23:08:43\n",
       "2017-02-03 23:08:44   2017-02-03 23:08:44\n",
       "2017-02-03 23:08:45   2017-02-03 23:08:45\n",
       "2017-02-03 23:08:46   2017-02-03 23:08:46\n",
       "2017-02-03 23:08:47   2017-02-03 23:08:47\n",
       "2017-02-03 23:08:48   2017-02-03 23:08:48\n",
       "Name: Timestamp, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amiller\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "ServiceDay = date(2017,2,3)\n",
    "\n",
    "# Compares the timing of the intermediate stop points of the trips and calculates an average time variance(RMS) for each\n",
    "# candidate trip\n",
    "\n",
    "# Find all stop times for each trip\n",
    "TripTimingPoints = pd.merge(SecondFilterTrips,Schedule.stop_times_by_date(ServiceDay),on='trip_id')\n",
    "TripTimingPoints = pd.merge(TripTimingPoints,Schedule.stops, on='stop_id')\n",
    "\n",
    "# The timing point filter requires that the timing point variable is set otherwise all stops are compared\n",
    "#if len(TripTimingPoints[TripTimingPoints.timepoint == 1]) > 1:\n",
    "#    TripTimingPoints = TripTimingPoints[TripTimingPoints.timepoint == 1].copy()\n",
    "    \n",
    "# Create a Point geometry object for each stop to fix it in space and time\n",
    "TripTimingPoints['geometry'] = TripTimingPoints.apply(lambda x: Point(float(x.stop_lon), float(x.stop_lat)), axis=1)\n",
    "TripTimingPoints = GeoDataFrame(TripTimingPoints)\n",
    "\n",
    "# Reproject the points to BC Albers:3005(meters)\n",
    "TripTimingPoints.crs = {'init': 'epsg:4326', 'no_defs': True}\n",
    "TripTimingPoints.to_crs(epsg=3005, inplace=True)\n",
    "\n",
    "def find_TP_match(row,apc_data):\n",
    "    \"\"\"\n",
    "        Takes a trip timing point and selects a window of APC data based on the defined interval to scan for potential \n",
    "        matches. Returns the timestamp from the closest record where the bus was within the specified distance of the \n",
    "        timing point location OR returns None if no potential matches are found.\n",
    "    \"\"\"\n",
    "    hour = int(row.arrival_time[0:2])\n",
    "    minute = int(row.arrival_time[3:5])\n",
    "    second = int(row.arrival_time[6:8])\n",
    "    \n",
    "    if hour < 24:\n",
    "        scheduled = datetime.combine(ServiceDay,time(hour,minute,second))\n",
    "    else:\n",
    "        hour -= 24\n",
    "        scheduled = datetime.combine(ServiceDay,time(hour,minute,second)) + timedelta(1)\n",
    "    \n",
    "    lower_bound = scheduled-timedelta(minutes=TIME_TOLERANCE)\n",
    "    upper_bound = scheduled+timedelta(minutes=TIME_TOLERANCE)\n",
    "    \n",
    "    \n",
    "    # create a subset of APC data for the requested time period i.e. Plus or minus the TIME_TOLERANCE \n",
    "    # from the scheduled stop time\n",
    "    possible_timing_points=apc_data[\n",
    "            lower_bound:upper_bound\n",
    "    ].copy()\n",
    "    \n",
    "    # Check distance.  Adjust DRIVEBY_TOLERANCE so that we have a reasonable chance of catching \"Drive By\" datapoints \n",
    "    matching_timing_points = possible_timing_points[\n",
    "            possible_timing_points.geometry.distance(row.geometry) < DRIVEBY_TOLERANCE\n",
    "    ]\n",
    "    \n",
    "    # find closest time \n",
    "    ##TODO Probably should be fixed to distance?\n",
    "    try:\n",
    "        matching_timing_points['deviation'] = matching_timing_points.apply(\n",
    "                lambda x: abs((scheduled - x.Timestamp).total_seconds()), axis=1\n",
    "        )\n",
    "        return matching_timing_points.deviation.min()\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "# Loop through the list of timing points and search for matching records in the data stream in order to calculate RMS\n",
    "TripTimingPoints['deviation'] = TripTimingPoints.apply(find_TP_match, args=(data,), axis=1)\n",
    "\n",
    "# Calculate the average scheduled stop time deviation for each candidate trip \n",
    "TripTimingPoints['squared_deviation'] = TripTimingPoints.apply(lambda x: x.deviation**2, axis=1)\n",
    "TripRMS = TripTimingPoints.groupby(['trip_id']).mean()\n",
    "TripRMS['TimeRMS'] = TripRMS.apply(lambda x: sqrt(x.squared_deviation),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# further refine the list of candidate trips by removing those greater than the allowed TIME_DEVIATION from the trip schedule\n",
    "# More useful for non-blocked matching\n",
    "ThirdFilterTrips = pd.merge(SecondFilterTrips,TripRMS.reset_index(),on='trip_id')\n",
    "ThirdFilterTrips = ThirdFilterTrips[ThirdFilterTrips.TimeRMS < TIME_DEVIATION.total_seconds()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Identify overlapping candidate trips\n",
    "def find_conflicts(row, TripSet):\n",
    "    return str([trip for trip in list(TripSet.apply(lambda x: x.trip_id if row.start_time < x.start_time < row.end_time or row.start_time < x.end_time < row.end_time else None,axis=1))if trip is not None])\n",
    "FourthFilterTrips = ThirdFilterTrips\n",
    "FourthFilterTrips['conflicts_with'] = ThirdFilterTrips.apply(find_conflicts, args=(ThirdFilterTrips,), axis=1)    \n",
    "FourthFilterTrips = FourthFilterTrips[FourthFilterTrips['conflicts_with'] =='[]'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_id_start_x</th>\n",
       "      <th>monday_x_start_x</th>\n",
       "      <th>tuesday_x_start_x</th>\n",
       "      <th>wednesday_x_start_x</th>\n",
       "      <th>thursday_x_start_x</th>\n",
       "      <th>friday_x_start_x</th>\n",
       "      <th>saturday_x_start_x</th>\n",
       "      <th>sunday_x_start_x</th>\n",
       "      <th>start_date_x_start_x</th>\n",
       "      <th>end_date_x_start_x</th>\n",
       "      <th>...</th>\n",
       "      <th>stop_code_end</th>\n",
       "      <th>location_type_end</th>\n",
       "      <th>parent_station_end</th>\n",
       "      <th>stop_short_name_end_y</th>\n",
       "      <th>geometry_end_y</th>\n",
       "      <th>shape_id_y</th>\n",
       "      <th>geometry_y</th>\n",
       "      <th>actual_start_y</th>\n",
       "      <th>actual_end_y</th>\n",
       "      <th>trip_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aaKA1609-KASEP16-Weekday-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>...</td>\n",
       "      <td>104534</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastbound Laurier at Sifton</td>\n",
       "      <td>POINT (1399017.339253946 640692.671462765)</td>\n",
       "      <td>8-7-48</td>\n",
       "      <td>LINESTRING (1400380.599716809 645165.799602209...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 07:00:20   2017-02-03 07:...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 07:31:58   2017-02-03 07:...</td>\n",
       "      <td>06:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aaKA1609-KASEP16-Weekday-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>...</td>\n",
       "      <td>104534</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastbound Laurier at Sifton</td>\n",
       "      <td>POINT (1399017.339253946 640692.671462765)</td>\n",
       "      <td>8-7-48</td>\n",
       "      <td>LINESTRING (1400380.599716809 645165.799602209...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 07:07:55   2017-02-03 07:...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 07:32:00   2017-02-03 07:...</td>\n",
       "      <td>07:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aaKA1609-KASEP16-Weekday-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>...</td>\n",
       "      <td>104504</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lansdowne Exchange Bay C</td>\n",
       "      <td>POINT (1400341.569959427 645155.0774439623)</td>\n",
       "      <td>8-7-44</td>\n",
       "      <td>LINESTRING (1399026.299716809 640697.497602219...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 08:35:36   2017-02-03 08:...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 09:01:44   2017-02-03 09:...</td>\n",
       "      <td>08:23:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaKA1609-KASEP16-Weekday-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>...</td>\n",
       "      <td>104479</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lansdowne Exchange Bay D</td>\n",
       "      <td>POINT (1400360.931345826 645156.6326602336)</td>\n",
       "      <td>8-6-29</td>\n",
       "      <td>LINESTRING (1400380.599716809 645165.799602209...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 11:02:54   2017-02-03 11:...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 11:15:21   2017-02-03 11:...</td>\n",
       "      <td>11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaKA1609-KASEP16-Weekday-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>...</td>\n",
       "      <td>104747</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastbound 9150 block Dallas</td>\n",
       "      <td>POINT (1418073.518299596 644162.9146484142)</td>\n",
       "      <td>8-17-64</td>\n",
       "      <td>LINESTRING (1400258.299716799 645130.499602226...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 16:07:34   2017-02-03 16:...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 16:53:18   2017-02-03 16:...</td>\n",
       "      <td>16:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaKA1609-KASEP16-Weekday-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>...</td>\n",
       "      <td>104654</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lansdowne Exchange Bay E</td>\n",
       "      <td>POINT (1400352.219065559 645146.8865003213)</td>\n",
       "      <td>8-17-68</td>\n",
       "      <td>LINESTRING (1418203.098716853 644153.294602213...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 16:56:40   2017-02-03 16:...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 17:21:16   2017-02-03 17:...</td>\n",
       "      <td>17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaKA1609-KASEP16-Weekday-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>...</td>\n",
       "      <td>104585</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southbound Springhill at Gleneagles</td>\n",
       "      <td>POINT (1398014.604520974 642321.7419424163)</td>\n",
       "      <td>8-9-38</td>\n",
       "      <td>LINESTRING (1400380.599716809 645165.799602209...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 17:33:22   2017-02-03 17:...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 18:03:28   2017-02-03 18:...</td>\n",
       "      <td>17:37:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaKA1609-KASEP16-Weekday-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>...</td>\n",
       "      <td>104577</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lansdowne Exchange Bay B</td>\n",
       "      <td>POINT (1400317.711554821 645153.0494227738)</td>\n",
       "      <td>8-9-44</td>\n",
       "      <td>LINESTRING (1398017.602716806 642316.498602209...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 20:10:36   2017-02-03 20:...</td>\n",
       "      <td>Timestamp\n",
       "2017-02-03 20:39:07   2017-02-03 20:...</td>\n",
       "      <td>19:57:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 718 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            service_id_start_x  monday_x_start_x  tuesday_x_start_x  \\\n",
       "6  aaKA1609-KASEP16-Weekday-05                 1                  1   \n",
       "5  aaKA1609-KASEP16-Weekday-05                 1                  1   \n",
       "7  aaKA1609-KASEP16-Weekday-05                 1                  1   \n",
       "4  aaKA1609-KASEP16-Weekday-05                 1                  1   \n",
       "2  aaKA1609-KASEP16-Weekday-05                 1                  1   \n",
       "3  aaKA1609-KASEP16-Weekday-05                 1                  1   \n",
       "1  aaKA1609-KASEP16-Weekday-05                 1                  1   \n",
       "0  aaKA1609-KASEP16-Weekday-05                 1                  1   \n",
       "\n",
       "   wednesday_x_start_x  thursday_x_start_x  friday_x_start_x  \\\n",
       "6                    1                   1                 1   \n",
       "5                    1                   1                 1   \n",
       "7                    1                   1                 1   \n",
       "4                    1                   1                 1   \n",
       "2                    1                   1                 1   \n",
       "3                    1                   1                 1   \n",
       "1                    1                   1                 1   \n",
       "0                    1                   1                 1   \n",
       "\n",
       "   saturday_x_start_x  sunday_x_start_x start_date_x_start_x  \\\n",
       "6                   0                 0           2017-01-24   \n",
       "5                   0                 0           2017-01-24   \n",
       "7                   0                 0           2017-01-24   \n",
       "4                   0                 0           2017-01-24   \n",
       "2                   0                 0           2017-01-24   \n",
       "3                   0                 0           2017-01-24   \n",
       "1                   0                 0           2017-01-24   \n",
       "0                   0                 0           2017-01-24   \n",
       "\n",
       "  end_date_x_start_x    ...      stop_code_end  location_type_end  \\\n",
       "6         2017-04-28    ...             104534                  0   \n",
       "5         2017-04-28    ...             104534                  0   \n",
       "7         2017-04-28    ...             104504                  0   \n",
       "4         2017-04-28    ...             104479                  0   \n",
       "2         2017-04-28    ...             104747                  0   \n",
       "3         2017-04-28    ...             104654                  0   \n",
       "1         2017-04-28    ...             104585                  0   \n",
       "0         2017-04-28    ...             104577                  0   \n",
       "\n",
       "  parent_station_end                stop_short_name_end_y  \\\n",
       "6                NaN          Eastbound Laurier at Sifton   \n",
       "5                NaN          Eastbound Laurier at Sifton   \n",
       "7                NaN             Lansdowne Exchange Bay C   \n",
       "4                NaN             Lansdowne Exchange Bay D   \n",
       "2                NaN          Eastbound 9150 block Dallas   \n",
       "3                NaN             Lansdowne Exchange Bay E   \n",
       "1                NaN  Southbound Springhill at Gleneagles   \n",
       "0                NaN             Lansdowne Exchange Bay B   \n",
       "\n",
       "                                geometry_end_y  shape_id_y  \\\n",
       "6   POINT (1399017.339253946 640692.671462765)      8-7-48   \n",
       "5   POINT (1399017.339253946 640692.671462765)      8-7-48   \n",
       "7  POINT (1400341.569959427 645155.0774439623)      8-7-44   \n",
       "4  POINT (1400360.931345826 645156.6326602336)      8-6-29   \n",
       "2  POINT (1418073.518299596 644162.9146484142)     8-17-64   \n",
       "3  POINT (1400352.219065559 645146.8865003213)     8-17-68   \n",
       "1  POINT (1398014.604520974 642321.7419424163)      8-9-38   \n",
       "0  POINT (1400317.711554821 645153.0494227738)      8-9-44   \n",
       "\n",
       "                                          geometry_y  \\\n",
       "6  LINESTRING (1400380.599716809 645165.799602209...   \n",
       "5  LINESTRING (1400380.599716809 645165.799602209...   \n",
       "7  LINESTRING (1399026.299716809 640697.497602219...   \n",
       "4  LINESTRING (1400380.599716809 645165.799602209...   \n",
       "2  LINESTRING (1400258.299716799 645130.499602226...   \n",
       "3  LINESTRING (1418203.098716853 644153.294602213...   \n",
       "1  LINESTRING (1400380.599716809 645165.799602209...   \n",
       "0  LINESTRING (1398017.602716806 642316.498602209...   \n",
       "\n",
       "                                      actual_start_y  \\\n",
       "6  Timestamp\n",
       "2017-02-03 07:00:20   2017-02-03 07:...   \n",
       "5  Timestamp\n",
       "2017-02-03 07:07:55   2017-02-03 07:...   \n",
       "7  Timestamp\n",
       "2017-02-03 08:35:36   2017-02-03 08:...   \n",
       "4  Timestamp\n",
       "2017-02-03 11:02:54   2017-02-03 11:...   \n",
       "2  Timestamp\n",
       "2017-02-03 16:07:34   2017-02-03 16:...   \n",
       "3  Timestamp\n",
       "2017-02-03 16:56:40   2017-02-03 16:...   \n",
       "1  Timestamp\n",
       "2017-02-03 17:33:22   2017-02-03 17:...   \n",
       "0  Timestamp\n",
       "2017-02-03 20:10:36   2017-02-03 20:...   \n",
       "\n",
       "                                        actual_end_y  trip_time  \n",
       "6  Timestamp\n",
       "2017-02-03 07:31:58   2017-02-03 07:...   06:50:00  \n",
       "5  Timestamp\n",
       "2017-02-03 07:32:00   2017-02-03 07:...   07:20:00  \n",
       "7  Timestamp\n",
       "2017-02-03 09:01:44   2017-02-03 09:...   08:23:00  \n",
       "4  Timestamp\n",
       "2017-02-03 11:15:21   2017-02-03 11:...   11:00:00  \n",
       "2  Timestamp\n",
       "2017-02-03 16:53:18   2017-02-03 16:...   16:10:00  \n",
       "3  Timestamp\n",
       "2017-02-03 17:21:16   2017-02-03 17:...   17:00:00  \n",
       "1  Timestamp\n",
       "2017-02-03 18:03:28   2017-02-03 18:...   17:37:00  \n",
       "0  Timestamp\n",
       "2017-02-03 20:39:07   2017-02-03 20:...   19:57:00  \n",
       "\n",
       "[8 rows x 718 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MatchedTrips = pd.merge(FourthFilterTrips, AllTrips, on='trip_id')\n",
    "MatchedTrips['trip_time'] = MatchedTrips.start_time_x\n",
    "MatchedTrips.sort_values(by='trip_time')#[['block_id','trip_sequence','trip_id','route_id','trip_time','actual_start','actual_end','ShapeRMS_x','TimeRMS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'start_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-ee9344ac568c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMatchedTrips\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\amiller\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2667\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2669\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2671\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'start_time'"
     ]
    }
   ],
   "source": [
    "MatchedTrips.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
