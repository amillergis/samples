{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SET GLOBALS\n",
    "\n",
    "import os, csv , re\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "DB_ENGINE = create_engine('')\n",
    "OUTPUT_ROOT = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# APC Files are seperated into individual *.dat files broken down by system, data_type, date, and bus_id\n",
    "# This creates a listing of indivdual files represented in the APC_RAW_DATAPOINTS table.\n",
    "\n",
    "data = pd.read_sql('''\n",
    "        SELECT \n",
    "            system_id,record_type,file_date,bus_id \n",
    "        FROM apc_raw_datapoints \n",
    "        GROUP BY system_id,record_type,bus_id,file_date''',\n",
    "        DB_ENGINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This calculates the file path for each of the individual files represented in the APC_RAW_DATAPOINTS table.\n",
    "# This also checks to see whether or not the file exists and filters the list down to files needing to be exported.\n",
    "\n",
    "def filepath(row):\n",
    "    if row.record_type == 'appl':\n",
    "        return path.join(\n",
    "            OUTPUT_ROOT,\n",
    "            row.system_id,\n",
    "            'data_{0}'.format(row.record_type),\n",
    "            'apc',\n",
    "            row.file_date.strftime('%Y%m%d'),\n",
    "            '{0}.dat'.format(row.bus_id)\n",
    "        )\n",
    "        \n",
    "    if row.record_type == 'nova':\n",
    "        return path.join(\n",
    "            OUTPUT_ROOT,\n",
    "            row.system_id,\n",
    "            'data_{0}'.format(row.record_type),\n",
    "            row.file_date.strftime('%Y%m%d'),\n",
    "            '{0}.dat'.format(row.bus_id)\n",
    "        )\n",
    "            \n",
    "data['filepath'] = data.apply(filepath,axis=1)\n",
    "data['export'] = data.apply(lambda x: os.path.isfile(x.filepath), axis=1)\n",
    "exports = data[data['export']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exports.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.sub(r'\\\\\\d{4}.dat$', '', exports['filepath'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_leaf_dir(row):\n",
    "    leaf_dir = re.sub(r'\\\\[0-9]{4}.dat$', '', exports['filepath'].iloc[0])\n",
    "    \n",
    "    # Create Leaf directory\n",
    "    if row.record_type == 'appl':\n",
    "        if not os.path.exists(leaf_dir):\n",
    "            os.makedirs(leaf_dir)\n",
    "    elif row.record_type == 'nova':\n",
    "        if not os.path.exists(leaf_dir):\n",
    "            os.makedirs(leaf_dir)\n",
    "\n",
    "def writefile(row):\n",
    "    # Create dataframe with all records from the file in the row\n",
    "    export_df = pd.read_sql_query('''\n",
    "        SELECT \n",
    "            raw_record \n",
    "        FROM \n",
    "            apc_raw_datapoints \n",
    "        WHERE \n",
    "            file_date=TO_DATE(:file_date,'YYYY-MM-DD') \n",
    "        AND \n",
    "            bus_id=:bus_id\n",
    "        ORDER BY\n",
    "            line_num''',\n",
    "        DB_ENGINE,\n",
    "        params={\n",
    "            'file_date':str(row.file_date.date()),\n",
    "            'bus_id':row.bus_id\n",
    "        })\n",
    "    print('Writing {0} of {1} --- {2}'.format(row.name+1, len(exports), row.filepath))\n",
    "    export_df.to_csv(row.filepath,index=False,header=False,quoting=csv.QUOTE_NONE,sep=\"|\")\n",
    "    \n",
    "exports.apply(create_leaf_dir,axis=1)\n",
    "exports.apply(writefile,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
